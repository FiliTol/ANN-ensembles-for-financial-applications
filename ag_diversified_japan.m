clc
close all
clear all

format long

% =========================================================================
% MULTIPLE CLASSIFIER
% =========================================================================

results = importdata("data/diversified.csv");

% Number of times to run the ensemble method
runs = 3;

% Function to extract best hyperparameters
f = @extract_top_values;

%-----------
% JAPANESE |
% ----------

opts = delimitedTextImportOptions("NumVariables", 16);
opts.DataLines = [1, Inf];
opts.Delimiter = " ";
opts.VariableNames = ["A1", "A2", "A3", "A4", "A5", "A6", "A7", "A8", "A9", "A10", "A11", "A12", "A13", "A14", "A15", "TARGET"];
opts.VariableTypes = ["categorical", "double", "double", "categorical", "categorical", "categorical", "categorical", "double", "categorical", "categorical", "double", "categorical", "categorical", "double", "double", "categorical"];
opts.ImportErrorRule = "omitrow";
opts.MissingRule = "omitrow";
opts.ExtraColumnsRule = "ignore";
opts.EmptyLineRule = "read";
opts.ConsecutiveDelimitersRule = "join";
opts.LeadingDelimitersRule = "ignore";
opts = setvaropts(opts, ["A1", "A4", "A5", "A6", "A7", "A9", "A10", "A12", "A13", "TARGET"], "EmptyFieldRule", "auto");
japanese = readtable("data/japanese/original/data.dat", opts);
clear opts

A1 = categorical(japanese.A1);
A1_encoding = onehotencode(A1,2);
A4 = categorical(japanese.A4);
A4_encoding = onehotencode(A4,2);
A5 = categorical(japanese.A5);
A5_encoding = onehotencode(A5,2);
A6 = categorical(japanese.A6);
A6_encoding = onehotencode(A6,2);
A7 = categorical(japanese.A7);
A7_encoding = onehotencode(A7,2);
A9_encoding = double(categorical(japanese.A9));
A10_encoding = double(categorical(japanese.A10));
A12_encoding = double(categorical(japanese.A12));
A13 = categorical(japanese.A13);
A13_encoding = onehotencode(A13,2);
TARGET = double(categorical(japanese.TARGET));

japanese_df = horzcat(A1_encoding(:,1:3),...
    normalize(japanese.A2),...
    normalize(japanese.A3),...
    A4_encoding(:,1:4),...
    A5_encoding(:,1:4),...
    A6_encoding(:,1:15),...
    A7_encoding(:,1:10),...
    normalize(japanese.A8),...
    A9_encoding(:,1),...
    A10_encoding(:,1),...
    normalize(japanese.A11),...
    A12_encoding(:,1),...
    A13_encoding(:,1:3),...
    normalize(japanese.A14),...
    normalize(japanese.A15),...
    TARGET(:,1));

clear A1 A10_encoding A12_encoding A13 A13_encoding A1_encoding A4 A4_encoding...
    A5 A5_encoding A6 A6_encoding A7 A7_encoding A9_encoding japanese TARGET

% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% From now on, for every different number of multiple classifiers used for
% the majority voting process, a new dataset must be created. The new
% dataset is based on the number of classifiers in such a manner that
% every different model used for the classifiers is fueled with a different
% not-intersecting subset of observations. Lastly, a testing subset is
% extracted; the testing dataset is proportional to the train datasets,
% such that it contains half of the observations used for the train
% datasets.

% Clearly, the more the classifiers used, the less observations will be
% included in each model's train set. The assumption given in the paper is
% that the poor performance of diversified multiple classifiers is tied to
% the insufficient size of training sets, especially for classifiers with
% more models.


% -------------------------------------------------------------------------
% 3 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/7);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_test = japanese_df(r*6+1:end,1:end-1);
Y_test = japanese_df(r*6+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,3).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,3).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,3).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,3).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,3).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,3).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test), net2.predict(X_test), net3.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_3 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_3;

end

accuracy_best_of_3 = mean(reserve);

results(2,4) = accuracy_best_of_3;

clear accuracy_best_of_3 final_decision i net1 net2 net3 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 Y_d1 Y_d2 Y_d3

% -------------------------------------------------------------------------
% 5 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/11);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);

X_test = japanese_df(r*10+1:end,1:end-1);
Y_test = japanese_df(r*10+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,5).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,5).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,5).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,5).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,5).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,5).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,5).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,5).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,5).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,5).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_5 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_5;

end

accuracy_best_of_5 = mean(reserve);

results(3,4) = accuracy_best_of_5;


clear accuracy_best_of_5 final_decision i net1 net2 net3 net4 net5 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5

% -------------------------------------------------------------------------
% 7 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/15);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);
X_d6 = japanese_df(r*10+1:r*12,1:end-1);
Y_d6 = japanese_df(r*10+1:r*12,end);
X_d7 = japanese_df(r*12+1:r*14,1:end-1);
Y_d7 = japanese_df(r*12+1:r*14,end);

X_test = japanese_df(r*14+1:end,1:end-1);
Y_test = japanese_df(r*14+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,7).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,7).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,7).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,7).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,7).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(5,7).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(5,7).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(5,7).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_7 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_7;

end

accuracy_best_of_7 = mean(reserve);

results(4,4) = accuracy_best_of_7;

clear accuracy_best_of_7 final_decision i net1 net2 net3 net4 net5 net6 net7 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6 X_d7 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7

% -------------------------------------------------------------------------
% 9 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/19);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);
X_d6 = japanese_df(r*10+1:r*12,1:end-1);
Y_d6 = japanese_df(r*10+1:r*12,end);
X_d7 = japanese_df(r*12+1:r*14,1:end-1);
Y_d7 = japanese_df(r*12+1:r*14,end);
X_d8 = japanese_df(r*14+1:r*16,1:end-1);
Y_d8 = japanese_df(r*14+1:r*16,end);
X_d9 = japanese_df(r*16+1:r*18,1:end-1);
Y_d9 = japanese_df(r*16+1:r*18,end);

X_test = japanese_df(r*18+1:end,1:end-1);
Y_test = japanese_df(r*18+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,9).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,9).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,9).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,9).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,9).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(5,9).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(5,9).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(5,9).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(5,9).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(5,9).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_9 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_9;

end

accuracy_best_of_9 = mean(reserve);

results(5,4) = accuracy_best_of_9;

clear accuracy_best_of_9 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9

% -------------------------------------------------------------------------
% 11 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/23);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);
X_d6 = japanese_df(r*10+1:r*12,1:end-1);
Y_d6 = japanese_df(r*10+1:r*12,end);
X_d7 = japanese_df(r*12+1:r*14,1:end-1);
Y_d7 = japanese_df(r*12+1:r*14,end);
X_d8 = japanese_df(r*14+1:r*16,1:end-1);
Y_d8 = japanese_df(r*14+1:r*16,end);
X_d9 = japanese_df(r*16+1:r*18,1:end-1);
Y_d9 = japanese_df(r*16+1:r*18,end);
X_d10 = japanese_df(r*18+1:r*20,1:end-1);
Y_d10 = japanese_df(r*18+1:r*20,end);
X_d11 = japanese_df(r*20+1:r*22,1:end-1);
Y_d11 = japanese_df(r*20+1:r*22,end);

X_test = japanese_df(r*22+1:end,1:end-1);
Y_test = japanese_df(r*22+1:end,end);


reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,11).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,11).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,11).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,11).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,11).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(5,11).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(5,11).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(5,11).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(5,11).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(5,11).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(5,11).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(5,11).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_11 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_11;

end

accuracy_best_of_11 = mean(reserve);

results(6,4) = accuracy_best_of_11;


clear accuracy_best_of_11 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 X_d10 X_d11 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10 Y_d11


% -------------------------------------------------------------------------
% 13 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/27);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);
X_d6 = japanese_df(r*10+1:r*12,1:end-1);
Y_d6 = japanese_df(r*10+1:r*12,end);
X_d7 = japanese_df(r*12+1:r*14,1:end-1);
Y_d7 = japanese_df(r*12+1:r*14,end);
X_d8 = japanese_df(r*14+1:r*16,1:end-1);
Y_d8 = japanese_df(r*14+1:r*16,end);
X_d9 = japanese_df(r*16+1:r*18,1:end-1);
Y_d9 = japanese_df(r*16+1:r*18,end);
X_d10 = japanese_df(r*18+1:r*20,1:end-1);
Y_d10 = japanese_df(r*18+1:r*20,end);
X_d11 = japanese_df(r*20+1:r*22,1:end-1);
Y_d11 = japanese_df(r*20+1:r*22,end);
X_d12 = japanese_df(r*22+1:r*24,1:end-1);
Y_d12 = japanese_df(r*22+1:r*24,end);
X_d13 = japanese_df(r*24+1:r*26,1:end-1);
Y_d13 = japanese_df(r*24+1:r*26,end);

X_test = japanese_df(r*26+1:end,1:end-1);
Y_test = japanese_df(r*26+1:end,end);


reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,13).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,13).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,13).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,13).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,13).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(5,13).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(5,13).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(5,13).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(5,13).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(5,13).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(5,13).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    net12 = fitcnet(X_d12, Y_d12,...
        'LayerSizes', f(5,13).Var2(12),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(12),...
        'LayerBiasesInitializer','ones');
    
    net13 = fitcnet(X_d13, Y_d13,...
        'LayerSizes', f(5,13).Var2(13),...
        'Activations','tanh',...
        'IterationLimit',f(5,13).Var1(13),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test),...
        net12.predict(X_test),...
        net13.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_13 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_13;

end

accuracy_best_of_13 = mean(reserve);

results(7,4) = accuracy_best_of_13;


clear accuracy_best_of_13 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 net12 net13 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 X_d10 X_d11 X_d12 X_d13 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10 Y_d11 Y_d12 Y_d13

% -------------------------------------------------------------------------
% 15 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(japanese_df)/31);
r = r(1);

X_d1 = japanese_df(1:r*2,1:end-1);
Y_d1 = japanese_df(1:r*2,end);
X_d2 = japanese_df(r*2+1:r*4,1:end-1);
Y_d2 = japanese_df(r*2+1:r*4,end);
X_d3 = japanese_df(r*4+1:r*6,1:end-1);
Y_d3 = japanese_df(r*4+1:r*6,end);
X_d4 = japanese_df(r*6+1:r*8,1:end-1);
Y_d4 = japanese_df(r*6+1:r*8,end);
X_d5 = japanese_df(r*8+1:r*10,1:end-1);
Y_d5 = japanese_df(r*8+1:r*10,end);
X_d6 = japanese_df(r*10+1:r*12,1:end-1);
Y_d6 = japanese_df(r*10+1:r*12,end);
X_d7 = japanese_df(r*12+1:r*14,1:end-1);
Y_d7 = japanese_df(r*12+1:r*14,end);
X_d8 = japanese_df(r*14+1:r*16,1:end-1);
Y_d8 = japanese_df(r*14+1:r*16,end);
X_d9 = japanese_df(r*16+1:r*18,1:end-1);
Y_d9 = japanese_df(r*16+1:r*18,end);
X_d10 = japanese_df(r*18+1:r*20,1:end-1);
Y_d10 = japanese_df(r*18+1:r*20,end);
X_d11 = japanese_df(r*20+1:r*22,1:end-1);
Y_d11 = japanese_df(r*20+1:r*22,end);
X_d12 = japanese_df(r*22+1:r*24,1:end-1);
Y_d12 = japanese_df(r*22+1:r*24,end);
X_d13 = japanese_df(r*24+1:r*26,1:end-1);
Y_d13 = japanese_df(r*24+1:r*26,end);
X_d14 = japanese_df(r*26+1:r*28,1:end-1);
Y_d14 = japanese_df(r*26+1:r*28,end);
X_d15 = japanese_df(r*28+1:r*30,1:end-1);
Y_d15 = japanese_df(r*28+1:r*30,end);

X_test = japanese_df(r*30+1:end,1:end-1);
Y_test = japanese_df(r*30+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(5,15).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(5,15).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(5,15).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(5,15).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(5,15).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(5,15).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(5,15).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(5,15).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(5,15).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(5,15).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(5,15).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    net12 = fitcnet(X_d12, Y_d12,...
        'LayerSizes', f(5,15).Var2(12),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(12),...
        'LayerBiasesInitializer','ones');
    
    net13 = fitcnet(X_d13, Y_d13,...
        'LayerSizes', f(5,15).Var2(13),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(13),...
        'LayerBiasesInitializer','ones');
    
    net14 = fitcnet(X_d14, Y_d14,...
        'LayerSizes', f(5,15).Var2(14),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(14),...
        'LayerBiasesInitializer','ones');
    
    net15 = fitcnet(X_d15, Y_d15,...
        'LayerSizes', f(5,15).Var2(15),...
        'Activations','tanh',...
        'IterationLimit',f(5,15).Var1(15),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test),...
        net12.predict(X_test),...
        net13.predict(X_test),...
        net14.predict(X_test),...
        net15.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_15 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_15;

end

accuracy_best_of_15 = mean(reserve);

results(8,4) = accuracy_best_of_15;

clear accuracy_best_of_15 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 net12 net13 net14 net15 prediction reserve X_test...
    Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6 X_d7 X_d8 X_d9 X_d10 X_d11 X_d12...
    X_d13 X_d14 X_d15 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10...
    Y_d11 Y_d12 Y_d13 Y_d14 Y_d15

% Save results into a table to be used also for other datasets
writematrix(results,'data/diversified.csv')





















function top_n_values = extract_top_values(column_num, n)
    T = readtable("data/single.csv");
    
    % Choose the column based on which you want to extract the top values
    column_of_interest = ['Var', num2str(column_num)];
    
    % Sort the table based on the chosen column
    sorted_T = sortrows(T, column_of_interest, 'descend');
    
    % Extract the top n rows
    top_n_rows = sorted_T(1:n, :);
    
    % Extract the values from the first and second columns of the top n rows
    top_n_values = top_n_rows(:, {'Var1', 'Var2'});
end