@article{TSAI20082639,
  title = {Using neural network ensembles for bankruptcy prediction and credit
           scoring},
  journal = {Expert Systems with Applications},
  volume = {34},
  number = {4},
  pages = {2639-2649},
  year = {2008},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2007.05.019},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417407001558},
  author = {Chih-Fong Tsai and Jhen-Wei Wu},
  keywords = {Bankruptcy prediction, Credit scoring, Neural networks, Classifier
              ensembles},
  abstract = {Bankruptcy prediction and credit scoring have long been regarded
              as critical topics and have been studied extensively in the
              accounting and finance literature. Artificial intelligence and
              machine learning techniques have been used to solve these financial
              decision-making problems. The multilayer perceptron (MLP) network
              trained by the back-propagation learning algorithm is the mostly
              used technique for financial decision-making problems. In addition,
              it is usually superior to other traditional statistical models.
              Recent studies suggest combining multiple classifiers (or
              classifier ensembles) should be better than single classifiers.
              However, the performance of multiple classifiers in bankruptcy
              prediction and credit scoring is not fully understood. In this
              paper, we investigate the performance of a single classifier as the
              baseline classifier to compare with multiple classifiers and
              diversified multiple classifiers by using neural networks based on
              three datasets. By comparing with the single classifier as the
              benchmark in terms of average prediction accuracy, the multiple
              classifiers only perform better in one of the three datasets. The
              diversified multiple classifiers trained by not only different
              classifier parameters but also different sets of training data
              perform worse in all datasets. However, for the Type I and Type II
              errors, there is no exact winner. We suggest that it is better to
              consider these three classifier architectures to make the optimal
              financial decision.},
}

