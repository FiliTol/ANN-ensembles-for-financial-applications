\documentclass[12pt]{beamer}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings} % Include the listings package for code listings

% Define MATLAB code listing settings
\lstdefinestyle{matlab}{
    language=Matlab, % Set the programming language to MATLAB
    basicstyle=\small\ttfamily, % Set the font style for the code
    numbers=left, % Display line numbers
    numberstyle=\tiny, % Set the style for line numbers
    numbersep=5pt, % Set the distance of line numbers from the code
    frame=single, % Add a frame around the code
    framexleftmargin=8mm, % Set the margin for the frame
    captionpos=b % Position the caption at the bottom of the code listing
}

\title[EM2091]{Review and matlab implementation of the paper:} % Text in square brackets is displayed in the footer
\subtitle{\textit{Using neural network ensembles for bankruptcy prediction and credit scoring}}
\author[Filippo Tolin]{
    \href{mailto:874631@stud.unive.it}{Filippo Tolin}
}
\institute[Ca' Foscari]{Ca' Foscari University of Venice }
\date{March 28, 2024}


\usepackage{template}


\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Summary}
\tableofcontents 
\end{frame}

\section{Paper review}

\subsection{Goals}

\begin{frame}{Goals}
  \begin{itemize}
    \item Observe the performance differences between different ANN ensemble
      approaches, namely single classifiers,
      multiple classifiers and diversified multiple classifiers, with regards to based on a set
      credit scoring and bankruptcy detection. The study is based on three
      of heterogeneous datasets;
    \item Evaluate the three classifier architectures performance with regards to
      Type 1 error and Type 2 error.
  \end{itemize}
\end{frame}

\subsection{Tools}

\begin{frame}{Tools}
  \begin{itemize}
    \item Multilayer Perceptron feedforward Artificial Neural Network
      \begin{itemize}
        \item One \textbf{hidden} layer
        \item Five different values for the \textbf{hidden nodes} hyperparameter
        \item Four different values for the \textbf{training epochs} hyperparameter
      \end{itemize}
    \item Multiple classifiers with two techniques to compute them:
      \begin{enumerate}
        \item Best $n$ classifiers for every epoch
        \item Best $n$ classifiers among all the epochs
      \end{enumerate}
      \begin{block}{Note}
        Technique $1$ is only applicable to $n=3 \wedge n=5$,
        with $n \in [3,5,7,9,11,13,15]$. Multiple classifiers are based on \textbf{majority voting}.
      \end{block}
  \end{itemize}
\end{frame}

\subsection{Advancements vs previous works}

\begin{frame}{Advancements vs previous works}
  \begin{itemize}
    \item Employment of \textbf{multiple datasets} for system validation;
    \item Usage of \textbf{Type 1 and Type 2 errors} and not only average accuracy measures;
    \item Testing the classifiers performance on multiple classification tasks
      rather than a single one, specifically on \textbf{credit scoring} and \textbf{bankruptcy prediction}.
  \end{itemize}
\end{frame}

\begin{frame}{Brief remark}
\begin{itemize}
\item \textbf{Type 1} error is associated with \textbf{false positives};
\item \textbf{Type 2} error is associated with \textbf{false negatives}.
\end{itemize}

\begin{examples}
  \begin{itemize}
    \item \textit{Type 1}: the model classifies a credit-worthy client as a credit-risky one;
    \item \textit{Type 2}: the model classifiers a credit-risky client as a credit-worthy one.
  \end{itemize}
\end{examples}

\end{frame}

\subsection{Study 1,2,3}

\begin{frame}{Study 1: single vs multiple classifiers}
  \begin{itemize}
    \item Datasets are split into training (70\%) and test (10\%);
    \item For single classifiers the number of nodes is $nn \in [8,12,16,24,32]$
      and learning epochs $[50,100,200,300]$.
    \item Multiple classifers are build with the voting strategy combining the results
      of the top $n$ classifers, with $n \in [3,5,7,9,11,13,15]$.
  \end{itemize}
  \begin{block}{Takeout}
  On average, the single best classifer outperforms multiple classifers.
  \end{block}
\end{frame}

\begin{frame}{Study 1: single vs multiple classifiers}
  \begin{figure}
    \centering
    \subcaptionbox{Australian\label{fig:st1aus}}{\includegraphics[width=0.41\linewidth]{images/st1aus.png}}\hfill
    \subcaptionbox{German\label{fig:st1ger}}{\includegraphics[width=0.41\linewidth]{images/st1ger.png}}\hfill
    \subcaptionbox{Japanese\label{fig:st1jap}}{\includegraphics[width=0.41\linewidth]{images/st1jap.png}}
    \caption{Comparison between single classifiers and multiple classifiers.}
\end{figure}
\end{frame}



\begin{frame}{Study 2: single vs multiple vs diversified classifiers}
  \begin{itemize}
    \item Train-test dataset generation is different for diversified multiple classifiers.
      Specifically, every model composing
      the classifier is trained on a fraction of the observations from the same
      dataset, then the majority
      voting is executed using a test dataset;
    \item The procedure aims at ensuring \textbf{diversity} between classifiers.
  \end{itemize}

  \begin{block}{Takeout}
    The best single classifier is still, on average, a better classifier than
    the diversified multiple classifier (and the multiple classifier, as seen before).
  \end{block}

\end{frame}

\begin{frame}{Study 2: single vs multiple vs diversified classifiers}
  \begin{figure}
    \centering
    \subcaptionbox{Australian\label{fig:st2aus}}{\includegraphics[width=0.40\linewidth]{images/st2aus.png}}\hfill
    \subcaptionbox{German\label{fig:st2ger}}{\includegraphics[width=0.40\linewidth]{images/st2ger.png}}\hfill
    \subcaptionbox{Japanese\label{fig:st2jap}}{\includegraphics[width=0.40\linewidth]{images/st2jap.png}}
    \caption{Comparison between single, multiple and diversified classifiers.}
\end{figure}
\end{frame}



\begin{frame}{Study 3: Type 1 and Type 2 errors}
  \begin{itemize}
    \item In Study 1 and Study 2 the results of classifiers are compared based on
      the \textbf{accuracy} of the classifiers. Study 3 compares the models
      performance with regards to Type 1 and Type 2 errors.
  \end{itemize}

  \begin{block}{Takeout}
    This study highlights how single classifiers do not totally outperform multiple
    or diversified classifiers.
  \end{block}
\end{frame}

\begin{frame}{Study 3: Type 1 and Type 2 errors}
  \begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{images/error.png}
    \caption{Type 1 and Type 2 error across datasets and classifier architectures.}
\end{figure}
\end{frame}

\subsection{Conclusions}

\begin{frame}{Conclusions}
  \begin{itemize}
    \item If the performance is measured with \textbf{accuracy}, \textbf{single best neural
      network classifier is more suitable} for bankruptcy
      prediction and credit scoring tasks, if compared with multiple or diversified
      multiple neural network classfiers;
    \item If performance is measured with \textbf{type 1 and 2 errors}, there seems
      to be no \textbf{clear winner} among the model architectures analysed.
  \end{itemize}
\end{frame}

\section{A couple of remarks\dots}

\begin{frame}{A couple of remarks\dots}
  \begin{itemize}
    \item The methodology used to build the datasets for diversified multiple classifers
      could be associated with the poor performance by the classifiers. In fact
      the higher the $n$ the smaller the train-sets used for each models' training.
      This could lead to a lot of results variability;
    \item It's not clear why the authors used two methodologies to build the multiple
      classifiers even though one of them is applicable only to $n=3$ and $n=5$
      classifiers.
  \end{itemize}
\end{frame}

%------------------------------------------------
\section{Matlab implementation}
%------------------------------------------------

\subsection{Methodology}

\begin{frame}{Methodology}
  \begin{itemize}
    \item \textbf{Pre-processing}. The datasets used for the matlab implementation
      are (presumably) the same datasets used by the authors of the paper. The datasets
      pre-processing, specifically:
      \begin{itemize}
        \item \textbf{feature normalization}. In order to apply ANN, all the continuous
          features need min-max normalization;
        \item \textbf{one-hot-encoding}. In order to apply ANN, all the categorical
          features need a different encoding, specifically one-hot-encoding.
      \end{itemize}
    \item \textbf{Datasets}. The three datasets were retrieved from the UC Irvine Machine Learning Repository.
      \begin{itemize}
        \item Australian (690 x 15);
        \item German (1000 x 20);
        \item Japanese (690 x 16).
      \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Model}

\begin{frame}[fragile]{Model}
  \begin{lstlisting}[style=matlab]
epochs = [50 100 200 300];
hidden_nodes = [8 12 16 24 32];

net = fitcnet(X_train, Y_train,...
  'Activations','sigmoid',...
  'IterationLimit',epoch,...
  'LayerBiasesInitializer','ones');
  'LayerSizes', node,...
testAccuracy = 1 - loss(net,X_test,Y_test,...
"LossFun","classiferror");
  \end{lstlisting}
\end{frame}

\subsection{Single classifier}

\begin{frame}{Single classifier}
  \begin{block}{Methodology}
    For the single neural network classifier, the dataset is divided into test
    (70\%) and train (30\%); then the implementation execute a loop
    that tests all the possible combinations of hidden nodes and epochs.
  \end{block}
\end{frame}

\subsection{Multiple classifier}

\begin{frame}{Multiple classifiers}
  \begin{alertblock}{Note}
    Since there seem to not exist a \texttt{MATLAB} function for the multiple
    classifier for \texttt{fitcnet}, the implementation has been done by hand.
  \end{alertblock}

\begin{itemize}
  \item For every $n$ and dataset, $n$ models are trained based on the hyperparameters
    of best $n$ single classifiers;
  \item Then predictions are formulated by every model with the test dataset;
  \item The results of the predictions from $n$ models undergo
    the majority voting process, where the resulting vector is the vector of the
    $n$ multiple classifier predictions.
\end{itemize}
\end{frame}

\subsection{Diversified multiple classifier}

\begin{frame}{Diversified multiple classifier}
  \begin{itemize}
    \item Same structure of multiple classifier, but every model is trained on
      a different subset of observations from the dataset;
    \item The algorithm for diversified dataset creation is the following:

    \begin{block}{Dataset splitting}
       $split = \frac{nrows(dataset)}{2 \times n +1}$, then for every classifier
      the train dataset is $2 \times split$. Test dataset is of size $split$.
      \end{block}
  \end{itemize}
\end{frame}

\subsection{Results of Study 1 and 2}

\begin{frame}{Results of Study 1 and 2}
    \begin{figure}
    \includegraphics[width=0.6\linewidth]{../../data/graph.png}
    \end{figure}
\end{frame}

\begin{frame}{Results of Study 1 and 2}
  \begin{block}{Takeout}
    From this results can be confirmed that the best single classifier ANN, on
    average, performs
    better than the multiple and diversified multiple classifiers across the three
    datasets and the different classification tasks.
  \end{block}

  \begin{alertblock}{Note}
    The exception of multiple classifiers outperforming the single classifiers
    happens for the japanese dataset, whereas on the paper implementation happens
    with the german dataset.
  \end{alertblock}
\end{frame}

\subsection{Type 1 and 2 error}
\begin{frame}{Type 1 and 2 error: setup}
\begin{itemize}
  \item \textbf{Single classifier}. For every combination of hyperparameters, the
    confusion matrix is computed and thus derived the type 1 and 2 errors;
  \item \textbf{Multiple classifier}. The same procedure is executed for every
    classifier.
\end{itemize}
\end{frame}

\begin{frame}{Type 1 and 2 error: results}
  \begin{table}[htbp]
  \centering
  \caption{Single classifier}
    \begin{tabular}{cccc}
    \textbf{Error type} & \textbf{Australian} & \textbf{German} & \textbf{Japanese} \\
    1 & 0.2107  & 0.1787  & 0.2309 \\
    2 & 0.2248  & 0.5384  & 0.1675 \\
    \bottomrule
    \end{tabular}%
  \label{tab:data1}%
\end{table}%

\begin{table}[htbp]
  \centering
  \caption{Multiple classifier}
    \begin{tabular}{cccc}
    \textbf{Error type} & \textbf{Australian} & \textbf{German} & \textbf{Japanese} \\
    1 & 0.0900 & 0.1605 & 0.1771 \\
    2 & 0.1977 & 0.5373 & 0.1045 \\
    \bottomrule
    \end{tabular}%
  \label{tab:data2}%
\end{table}%

\end{frame}

\begin{frame}{Type 1 and 2 errors: results}
  \begin{block}{Takeout}
    As according to the paper authors and findings, the performance measured with
    type 1 and 2 error leaves more doubts about a clear winner model architecture.
  \end{block}
\end{frame}


\begin{frame}{References}
    % Beamer does not support BibTeX so references must be inserted manually as below
    \footnotesize{
        \begin{thebibliography}{99}
            \bibitem[Chih-Fong Tsai, Jhen-Wei Wu, 2008]{p1} Chih-Fong Tsai, Jhen-Wei Wu (2008)
            \newblock Using neural network ensembles for bankruptcy prediction and credit
           scoring
            \newblock \emph{Expert Systems with Applications} 34(4), 2639 -- 2649.
        \end{thebibliography}
    }
\end{frame}


\end{document}
