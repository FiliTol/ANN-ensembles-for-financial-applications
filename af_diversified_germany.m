clc
close all
clear all

format long

% =========================================================================
% MULTIPLE CLASSIFIER
% =========================================================================

results = importdata("data/diversified.csv");

% Number of times to run the ensemble method
runs = 3;

% Function to extract best hyperparameters
f = @extract_top_values;

%---------
% GERMAN |
% --------

% Replicate the data preparation as for single classifier
german = importdata('data/german/german.dat');

A1 = categorical(german.textdata(:,1));
A1_encoding = onehotencode(A1,2);
A3 = categorical(german.textdata(:,3));
A3_encoding = onehotencode(A3,2);
A4 = categorical(german.textdata(:,4));
A4_encoding = onehotencode(A4,2);
A6 = categorical(german.textdata(:,6));
A6_encoding = onehotencode(A6,2);
A7 = categorical(german.textdata(:,7));
A7_encoding = onehotencode(A7,2);
A9 = categorical(german.textdata(:,9));
A9_encoding = onehotencode(A9,2);
A10 = categorical(german.textdata(:,10));
A10_encoding = onehotencode(A10,2);
A12 = categorical(german.textdata(:,12));
A12_encoding = onehotencode(A12,2);
A14 = categorical(german.textdata(:,14));
A14_encoding = onehotencode(A14,2);
A15 = categorical(german.textdata(:,15));
A15_encoding = onehotencode(A15,2);
A17 = categorical(german.textdata(:,17));
A17_encoding = onehotencode(A17,2);
A19_encoding = double(categorical(german.textdata(:,19)));
A20_encoding = double(categorical(german.textdata(:,20)));
TARGET = double(categorical(german.data(:,1)));

german_df = horzcat(A1_encoding(:,1:4),...
    normalize(str2double(german.textdata(:,2))),...
    A3_encoding(:,1:5),...
    A4_encoding(:,1:10),...
    normalize(str2double(german.textdata(:,5))),...
    A6_encoding(:,1:5),...
    A7_encoding(:,1:5),...
    normalize(str2double(german.textdata(:,8))),...
    A9_encoding(:,1:4),...
    A10_encoding(:,1:3),...
    normalize(str2double(german.textdata(:,11))),...
    A12_encoding(:,1:4),...
    normalize(str2double(german.textdata(:,13))),...
    A14_encoding(:,1:3),...
    A15_encoding(:,1:3),...
    normalize(str2double(german.textdata(:,16))),...
    A17_encoding(:,1:4),...
    normalize(str2double(german.textdata(:,18))),...
    A19_encoding(:,1),...
    A20_encoding(:,1),...
    TARGET(:,1));

clear A1 A10 A10_encoding A12 A12_encoding A14 A14_encoding A15 A15_encoding...
    A17 A17_encoding A19_encoding A1_encoding A20_encoding A3 A3_encoding...
    A4 A4_encoding A6 A6_encoding A7 A7_encoding A9 A9_encoding german TARGET

% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% From now on, for every different number of multiple classifiers used for
% the majority voting process, a new dataset must be created. The new
% dataset is based on the number of classifiers in such a manner that
% every different model used for the classifiers is fueled with a different
% not-intersecting subset of observations. Lastly, a testing subset is
% extracted; the testing dataset is proportional to the train datasets,
% such that it contains half of the observations used for the train
% datasets.

% Clearly, the more the classifiers used, the less observations will be
% included in each model's train set. The assumption given in the paper is
% that the poor performance of diversified multiple classifiers is tied to
% the insufficient size of training sets, especially for classifiers with
% more models.


% -------------------------------------------------------------------------
% 3 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/7);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_test = german_df(r*6+1:end,1:end-1);
Y_test = german_df(r*6+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,3).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,3).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,3).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,3).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,3).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,3).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test), net2.predict(X_test), net3.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_3 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_3;

end

accuracy_best_of_3 = mean(reserve);

results(2,3) = accuracy_best_of_3;

clear accuracy_best_of_3 final_decision i net1 net2 net3 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 Y_d1 Y_d2 Y_d3

% -------------------------------------------------------------------------
% 5 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/11);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);

X_test = german_df(r*10+1:end,1:end-1);
Y_test = german_df(r*10+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,5).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,5).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,5).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,5).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,5).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,5).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,5).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,5).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,5).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,5).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_5 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_5;

end

accuracy_best_of_5 = mean(reserve);

results(3,3) = accuracy_best_of_5;


clear accuracy_best_of_5 final_decision i net1 net2 net3 net4 net5 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5

% -------------------------------------------------------------------------
% 7 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/15);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);
X_d6 = german_df(r*10+1:r*12,1:end-1);
Y_d6 = german_df(r*10+1:r*12,end);
X_d7 = german_df(r*12+1:r*14,1:end-1);
Y_d7 = german_df(r*12+1:r*14,end);

X_test = german_df(r*14+1:end,1:end-1);
Y_test = german_df(r*14+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,7).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,7).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,7).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,7).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,7).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(4,7).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(4,7).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(4,7).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_7 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_7;

end

accuracy_best_of_7 = mean(reserve);

results(4,3) = accuracy_best_of_7;

clear accuracy_best_of_7 final_decision i net1 net2 net3 net4 net5 net6 net7 prediction...
    reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6 X_d7 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7

% -------------------------------------------------------------------------
% 9 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/19);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);
X_d6 = german_df(r*10+1:r*12,1:end-1);
Y_d6 = german_df(r*10+1:r*12,end);
X_d7 = german_df(r*12+1:r*14,1:end-1);
Y_d7 = german_df(r*12+1:r*14,end);
X_d8 = german_df(r*14+1:r*16,1:end-1);
Y_d8 = german_df(r*14+1:r*16,end);
X_d9 = german_df(r*16+1:r*18,1:end-1);
Y_d9 = german_df(r*16+1:r*18,end);

X_test = german_df(r*18+1:end,1:end-1);
Y_test = german_df(r*18+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs
    
    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,9).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,9).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,9).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,9).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,9).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(4,9).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(4,9).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(4,9).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(4,9).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(4,9).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_9 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_9;

end

accuracy_best_of_9 = mean(reserve);

results(5,3) = accuracy_best_of_9;

clear accuracy_best_of_9 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9


% -------------------------------------------------------------------------
% 11 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/23);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);
X_d6 = german_df(r*10+1:r*12,1:end-1);
Y_d6 = german_df(r*10+1:r*12,end);
X_d7 = german_df(r*12+1:r*14,1:end-1);
Y_d7 = german_df(r*12+1:r*14,end);
X_d8 = german_df(r*14+1:r*16,1:end-1);
Y_d8 = german_df(r*14+1:r*16,end);
X_d9 = german_df(r*16+1:r*18,1:end-1);
Y_d9 = german_df(r*16+1:r*18,end);
X_d10 = german_df(r*18+1:r*20,1:end-1);
Y_d10 = german_df(r*18+1:r*20,end);
X_d11 = german_df(r*20+1:r*22,1:end-1);
Y_d11 = german_df(r*20+1:r*22,end);

X_test = german_df(r*22+1:end,1:end-1);
Y_test = german_df(r*22+1:end,end);


reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,11).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,11).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,11).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,11).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,11).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(4,11).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(4,11).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(4,11).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(4,11).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(4,11).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(4,11).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(4,11).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_11 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_11;

end

accuracy_best_of_11 = mean(reserve);

results(6,3) = accuracy_best_of_11;


clear accuracy_best_of_11 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 X_d10 X_d11 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10 Y_d11


% -------------------------------------------------------------------------
% 13 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/27);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);
X_d6 = german_df(r*10+1:r*12,1:end-1);
Y_d6 = german_df(r*10+1:r*12,end);
X_d7 = german_df(r*12+1:r*14,1:end-1);
Y_d7 = german_df(r*12+1:r*14,end);
X_d8 = german_df(r*14+1:r*16,1:end-1);
Y_d8 = german_df(r*14+1:r*16,end);
X_d9 = german_df(r*16+1:r*18,1:end-1);
Y_d9 = german_df(r*16+1:r*18,end);
X_d10 = german_df(r*18+1:r*20,1:end-1);
Y_d10 = german_df(r*18+1:r*20,end);
X_d11 = german_df(r*20+1:r*22,1:end-1);
Y_d11 = german_df(r*20+1:r*22,end);
X_d12 = german_df(r*22+1:r*24,1:end-1);
Y_d12 = german_df(r*22+1:r*24,end);
X_d13 = german_df(r*24+1:r*26,1:end-1);
Y_d13 = german_df(r*24+1:r*26,end);

X_test = german_df(r*26+1:end,1:end-1);
Y_test = german_df(r*26+1:end,end);


reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,13).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,13).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,13).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,13).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,13).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(4,13).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(4,13).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(4,13).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(4,13).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(4,13).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(4,13).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    net12 = fitcnet(X_d12, Y_d12,...
        'LayerSizes', f(4,13).Var2(12),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(12),...
        'LayerBiasesInitializer','ones');
    
    net13 = fitcnet(X_d13, Y_d13,...
        'LayerSizes', f(4,13).Var2(13),...
        'Activations','tanh',...
        'IterationLimit',f(4,13).Var1(13),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test),...
        net12.predict(X_test),...
        net13.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_13 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_13;

end

accuracy_best_of_13 = mean(reserve);

results(7,3) = accuracy_best_of_13;


clear accuracy_best_of_13 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 net12 net13 prediction reserve X_test Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6...
    X_d7 X_d8 X_d9 X_d10 X_d11 X_d12 X_d13 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10 Y_d11 Y_d12 Y_d13

% -------------------------------------------------------------------------
% 15 classifiers
% -------------------------------------------------------------------------

% The number of splits is computed as n*2+1. Then every training split is
% composed by r*2 observations and the test split is composed by r
% observations.

r = floor(size(german_df)/31);
r = r(1);

X_d1 = german_df(1:r*2,1:end-1);
Y_d1 = german_df(1:r*2,end);
X_d2 = german_df(r*2+1:r*4,1:end-1);
Y_d2 = german_df(r*2+1:r*4,end);
X_d3 = german_df(r*4+1:r*6,1:end-1);
Y_d3 = german_df(r*4+1:r*6,end);
X_d4 = german_df(r*6+1:r*8,1:end-1);
Y_d4 = german_df(r*6+1:r*8,end);
X_d5 = german_df(r*8+1:r*10,1:end-1);
Y_d5 = german_df(r*8+1:r*10,end);
X_d6 = german_df(r*10+1:r*12,1:end-1);
Y_d6 = german_df(r*10+1:r*12,end);
X_d7 = german_df(r*12+1:r*14,1:end-1);
Y_d7 = german_df(r*12+1:r*14,end);
X_d8 = german_df(r*14+1:r*16,1:end-1);
Y_d8 = german_df(r*14+1:r*16,end);
X_d9 = german_df(r*16+1:r*18,1:end-1);
Y_d9 = german_df(r*16+1:r*18,end);
X_d10 = german_df(r*18+1:r*20,1:end-1);
Y_d10 = german_df(r*18+1:r*20,end);
X_d11 = german_df(r*20+1:r*22,1:end-1);
Y_d11 = german_df(r*20+1:r*22,end);
X_d12 = german_df(r*22+1:r*24,1:end-1);
Y_d12 = german_df(r*22+1:r*24,end);
X_d13 = german_df(r*24+1:r*26,1:end-1);
Y_d13 = german_df(r*24+1:r*26,end);
X_d14 = german_df(r*26+1:r*28,1:end-1);
Y_d14 = german_df(r*26+1:r*28,end);
X_d15 = german_df(r*28+1:r*30,1:end-1);
Y_d15 = german_df(r*28+1:r*30,end);

X_test = german_df(r*30+1:end,1:end-1);
Y_test = german_df(r*30+1:end,end);

reserve = zeros(runs,1);

for i = 1:runs

    net1 = fitcnet(X_d1, Y_d1,...
        'LayerSizes', f(4,15).Var2(1),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(1),...
        'LayerBiasesInitializer','ones');
    
    net2 = fitcnet(X_d2, Y_d2,...
        'LayerSizes', f(4,15).Var2(2),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(2),...
        'LayerBiasesInitializer','ones');
    
    net3 = fitcnet(X_d3, Y_d3,...
        'LayerSizes', f(4,15).Var2(3),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(3),...
        'LayerBiasesInitializer','ones');
    
    net4 = fitcnet(X_d4, Y_d4,...
        'LayerSizes', f(4,15).Var2(4),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(4),...
        'LayerBiasesInitializer','ones');
    
    net5 = fitcnet(X_d5, Y_d5,...
        'LayerSizes', f(4,15).Var2(5),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(5),...
        'LayerBiasesInitializer','ones');
    
    net6 = fitcnet(X_d6, Y_d6,...
        'LayerSizes', f(4,15).Var2(6),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(6),...
        'LayerBiasesInitializer','ones');
    
    net7 = fitcnet(X_d7, Y_d7,...
        'LayerSizes', f(4,15).Var2(7),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(7),...
        'LayerBiasesInitializer','ones');
    
    net8 = fitcnet(X_d8, Y_d8,...
        'LayerSizes', f(4,15).Var2(8),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(8),...
        'LayerBiasesInitializer','ones');
    
    net9 = fitcnet(X_d9, Y_d9,...
        'LayerSizes', f(4,15).Var2(9),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(9),...
        'LayerBiasesInitializer','ones');
    
    net10 = fitcnet(X_d10, Y_d10,...
        'LayerSizes', f(4,15).Var2(10),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(10),...
        'LayerBiasesInitializer','ones');
    
    net11 = fitcnet(X_d11, Y_d11,...
        'LayerSizes', f(4,15).Var2(11),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(11),...
        'LayerBiasesInitializer','ones');
    
    net12 = fitcnet(X_d12, Y_d12,...
        'LayerSizes', f(4,15).Var2(12),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(12),...
        'LayerBiasesInitializer','ones');
    
    net13 = fitcnet(X_d13, Y_d13,...
        'LayerSizes', f(4,15).Var2(13),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(13),...
        'LayerBiasesInitializer','ones');
    
    net14 = fitcnet(X_d14, Y_d14,...
        'LayerSizes', f(4,15).Var2(14),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(14),...
        'LayerBiasesInitializer','ones');
    
    net15 = fitcnet(X_d15, Y_d15,...
        'LayerSizes', f(4,15).Var2(15),...
        'Activations','tanh',...
        'IterationLimit',f(4,15).Var1(15),...
        'LayerBiasesInitializer','ones');
    
    
    % Thus by comparing the prediction with and using the majority vote
    % criteria:
    prediction = [net1.predict(X_test),...
        net2.predict(X_test),...
        net3.predict(X_test),...
        net4.predict(X_test),...
        net5.predict(X_test),...
        net6.predict(X_test),...
        net7.predict(X_test),...
        net8.predict(X_test),...
        net9.predict(X_test),...
        net10.predict(X_test),...
        net11.predict(X_test),...
        net12.predict(X_test),...
        net13.predict(X_test),...
        net14.predict(X_test),...
        net15.predict(X_test)];
    final_decision = mode(prediction,2);
    
    accuracy_best_of_15 = sum(final_decision == Y_test)/length(final_decision);

    reserve(i,1) = accuracy_best_of_15;

end

accuracy_best_of_15 = mean(reserve);

results(8,3) = accuracy_best_of_15;

clear accuracy_best_of_15 final_decision i net1 net2 net3 net4 net5 net6 net7...
    net8 net9 net10 net11 net12 net13 net14 net15 prediction reserve X_test...
    Y_test X_d1 X_d2 X_d3 X_d4 X_d5 X_d6 X_d7 X_d8 X_d9 X_d10 X_d11 X_d12...
    X_d13 X_d14 X_d15 Y_d1 Y_d2 Y_d3 Y_d4 Y_d5 Y_d6 Y_d7 Y_d8 Y_d9 Y_d10...
    Y_d11 Y_d12 Y_d13 Y_d14 Y_d15

% Save results into a table to be used also for other datasets
writematrix(results,'data/diversified.csv')























function top_n_values = extract_top_values(column_num, n)
    T = readtable("data/single.csv");
    
    % Choose the column based on which you want to extract the top values
    column_of_interest = ['Var', num2str(column_num)];
    
    % Sort the table based on the chosen column
    sorted_T = sortrows(T, column_of_interest, 'descend');
    
    % Extract the top n rows
    top_n_rows = sorted_T(1:n, :);
    
    % Extract the values from the first and second columns of the top n rows
    top_n_values = top_n_rows(:, {'Var1', 'Var2'});
end